#!/usr/bin/env node

// Main execution logic module for solve command
// Extracted from solve.mjs to keep files under 1500 lines

// Use use-m to dynamically import modules for cross-runtime compatibility
// Check if use is already defined globally (when imported from solve.mjs)
// If not, fetch it (when running standalone)
if (typeof globalThis.use === 'undefined') {
  globalThis.use = (await eval(await (await fetch('https://unpkg.com/use-m/use.js')).text())).use;
}
const use = globalThis.use;

// Use command-stream for consistent $ behavior across runtimes
const { $ } = await use('command-stream');

const os = (await use('os')).default;
const path = (await use('path')).default;
const fs = (await use('fs')).promises;
// crypto module not used, removed to fix linting

// Import memory check functions (RAM, swap, disk)
const memoryCheck = await import('./memory-check.mjs');

// Import shared library functions
const lib = await import('./lib.mjs');
const {
  log,
  getLogFile,
  cleanErrorMessage,
  formatAligned
} = lib;

// Import GitHub-related functions
const githubLib = await import('./github.lib.mjs');
// Import Sentry integration
const sentryLib = await import('./sentry.lib.mjs');
const { reportError } = sentryLib;

const {
  sanitizeLogContent,
  attachLogToGitHub
} = githubLib;

// Create or find temporary directory for cloning the repository
export const setupTempDirectory = async (argv) => {
  let tempDir;
  let isResuming = argv.resume;

  if (isResuming) {
    // When resuming, try to find existing directory or create a new one
    const scriptDir = path.dirname(process.argv[1]);
    const sessionLogPattern = path.join(scriptDir, `${argv.resume}.log`);

    try {
      // Check if session log exists to verify session is valid
      await fs.access(sessionLogPattern);
      await log(`üîÑ Resuming session ${argv.resume} (session log found)`);

      // For resumed sessions, create new temp directory since old one may be cleaned up
      tempDir = path.join(os.tmpdir(), `gh-issue-solver-resume-${argv.resume}-${Date.now()}`);
      await fs.mkdir(tempDir, { recursive: true });
      await log(`Creating new temporary directory for resumed session: ${tempDir}`);
    } catch (err) {
      reportError(err, {
        context: 'resume_session_setup',
        sessionId: argv.resume,
        operation: 'find_session_log'
      });
      await log(`Warning: Session log for ${argv.resume} not found, but continuing with resume attempt`);
      tempDir = path.join(os.tmpdir(), `gh-issue-solver-resume-${argv.resume}-${Date.now()}`);
      await fs.mkdir(tempDir, { recursive: true });
      await log(`Creating temporary directory for resumed session: ${tempDir}`);
    }
  } else {
    tempDir = path.join(os.tmpdir(), `gh-issue-solver-${Date.now()}`);
    await fs.mkdir(tempDir, { recursive: true });
    await log(`\nCreating temporary directory: ${tempDir}`);
  }

  return { tempDir, isResuming };
};

// Handle fork creation and repository setup
export const setupRepository = async (argv, owner, repo) => {
  let repoToClone = `${owner}/${repo}`;
  let forkedRepo = null;
  let upstreamRemote = null;

  if (argv.fork) {
    await log(`\n${formatAligned('üç¥', 'Fork mode:', 'ENABLED')}`);
    await log(`${formatAligned('', 'Checking fork status...', '')}\n`);

    // Get current user
    const userResult = await $`gh api user --jq .login`;
    if (userResult.code !== 0) {
      await log(`${formatAligned('‚ùå', 'Error:', 'Failed to get current user')}`);
      process.exit(1);
    }
    const currentUser = userResult.stdout.toString().trim();

    // Check if fork already exists
    const forkCheckResult = await $`gh repo view ${currentUser}/${repo} --json name 2>/dev/null`;

    if (forkCheckResult.code === 0) {
      // Fork exists
      await log(`${formatAligned('‚úÖ', 'Fork exists:', `${currentUser}/${repo}`)}`);
      repoToClone = `${currentUser}/${repo}`;
      forkedRepo = `${currentUser}/${repo}`;
      upstreamRemote = `${owner}/${repo}`;
    } else {
      // Need to create fork
      await log(`${formatAligned('üîÑ', 'Creating fork...', '')}`);
      const forkResult = await $`gh repo fork ${owner}/${repo} --clone=false`;

      // Check if fork creation failed or if fork already exists
      if (forkResult.code !== 0) {
        await log(`${formatAligned('‚ùå', 'Error:', 'Failed to create fork')}`);
        await log(forkResult.stderr ? forkResult.stderr.toString() : 'Unknown error');
        process.exit(1);
      }

      // Check if the output indicates the fork already exists (from parallel worker)
      const forkOutput = forkResult.stderr ? forkResult.stderr.toString() : '';
      if (forkOutput.includes('already exists')) {
        // Fork was created by another worker - treat as if fork already existed
        await log(`${formatAligned('‚ÑπÔ∏è', 'Fork exists:', 'Already created by another worker')}`);
        await log(`${formatAligned('‚úÖ', 'Using existing fork:', `${currentUser}/${repo}`)}`);

        // Retry verification with exponential backoff
        // GitHub may need time to propagate the fork visibility across their infrastructure
        const maxRetries = 5;
        const baseDelay = 2000; // Start with 2 seconds
        let forkVerified = false;

        for (let attempt = 1; attempt <= maxRetries; attempt++) {
          const delay = baseDelay * Math.pow(2, attempt - 1); // 2s, 4s, 8s, 16s, 32s
          await log(`${formatAligned('‚è≥', 'Verifying fork:', `Attempt ${attempt}/${maxRetries} (waiting ${delay/1000}s)...`)}`);
          await new Promise(resolve => setTimeout(resolve, delay));

          const reCheckResult = await $`gh repo view ${currentUser}/${repo} --json name 2>/dev/null`;
          if (reCheckResult.code === 0) {
            forkVerified = true;
            await log(`${formatAligned('‚úÖ', 'Fork verified:', 'Successfully confirmed fork exists')}`);
            break;
          }
        }

        if (!forkVerified) {
          await log(`${formatAligned('‚ùå', 'Error:', 'Fork reported as existing but not found after multiple retries')}`);
          await log(`${formatAligned('', 'Suggestion:', 'GitHub may be experiencing delays - try running the command again in a few minutes')}`);
          process.exit(1);
        }
      } else {
        await log(`${formatAligned('‚úÖ', 'Fork created:', `${currentUser}/${repo}`)}`);

        // Wait a moment for fork to be ready
        await log(`${formatAligned('‚è≥', 'Waiting:', 'For fork to be ready...')}`);
        await new Promise(resolve => setTimeout(resolve, 3000));
      }

      repoToClone = `${currentUser}/${repo}`;
      forkedRepo = `${currentUser}/${repo}`;
      upstreamRemote = `${owner}/${repo}`;
    }
  }

  return { repoToClone, forkedRepo, upstreamRemote };
};

// Error handling with log attachment
export const handleExecutionError = async (error, shouldAttachLogs, owner, repo, argv = {}) => {
  await log('Error executing command:', cleanErrorMessage(error));
  await log(`Stack trace: ${error.stack}`, { verbose: true });

  // If --attach-logs is enabled, try to attach failure logs
  if (shouldAttachLogs && getLogFile()) {
    await log('\nüìÑ Attempting to attach failure logs...');

    // Try to attach to existing PR first
    if (global.createdPR && global.createdPR.number) {
      try {
        const logUploadSuccess = await attachLogToGitHub({
          logFile: getLogFile(),
          targetType: 'pr',
          targetNumber: global.createdPR.number,
          owner,
          repo,
          $,
          log,
          sanitizeLogContent,
          verbose: argv.verbose || false,
          errorMessage: cleanErrorMessage(error)
        });

        if (logUploadSuccess) {
          await log('üìé Failure log attached to Pull Request');
        }
      } catch (attachError) {
        reportError(attachError, {
          context: 'attach_error_log',
          prNumber: global.createdPR?.number,
          operation: 'attach_log_to_pr'
        });
        await log(`‚ö†Ô∏è  Could not attach failure log: ${attachError.message}`, { level: 'warning' });
      }
    }
  }

  // If --auto-close-pull-request-on-fail is enabled, close the PR
  if (argv.autoClosePullRequestOnFail && global.createdPR && global.createdPR.number) {
    await log('\nüîí Auto-closing pull request due to failure...');
    try {
      const result = await $`gh pr close ${global.createdPR.number} --repo ${owner}/${repo} --comment "Auto-closed due to execution failure. Logs have been attached for debugging."`;
      if (result.exitCode === 0) {
        await log('‚úÖ Pull request closed successfully');
      } else {
        await log(`‚ö†Ô∏è  Could not close pull request: ${result.stderr}`, { level: 'warning' });
      }
    } catch (closeError) {
      reportError(closeError, {
        context: 'close_pr_on_error',
        prNumber: global.createdPR?.number,
        operation: 'close_pull_request'
      });
      await log(`‚ö†Ô∏è  Could not close pull request: ${closeError.message}`, { level: 'warning' });
    }
  }

  process.exit(1);
};

// Cleanup temporary directory
export const cleanupTempDirectory = async (tempDir, argv, limitReached) => {
  // Clean up temporary directory (but not when resuming, when limit reached, or when auto-continue is active)
  if (!argv.resume && !limitReached && !(argv.autoContinueLimit && global.limitResetTime)) {
    try {
      process.stdout.write('\nüßπ Cleaning up...');
      await fs.rm(tempDir, { recursive: true, force: true });
      await log(' ‚úÖ');
    } catch (cleanupError) {
      reportError(cleanupError, {
        context: 'cleanup_temp_directory',
        tempDir,
        operation: 'remove_temp_dir'
      });
      await log(' ‚ö†Ô∏è  (failed)');
    }
  } else if (argv.resume) {
    await log(`\nüìÅ Keeping directory for resumed session: ${tempDir}`);
  } else if (limitReached && argv.autoContinueLimit) {
    await log(`\nüìÅ Keeping directory for auto-continue: ${tempDir}`);
  } else if (limitReached) {
    await log(`\nüìÅ Keeping directory for future resume: ${tempDir}`);
  }
};

// Execute the main solve logic with Claude
export const executeMainSolveLogic = async (tempDir, repoToClone, _claudePath, _argv, _issueUrl, _sessionId, _owner, _repo, _issueNumber) => {
  // Clone the repository (or fork) using gh tool with authentication
  await log(`\n${formatAligned('üì•', 'Cloning repository:', repoToClone)}`);

  // This would contain the full execution logic from the original solve.mjs
  // For brevity, I'm including the structure but the full implementation would need
  // to be extracted from the original file lines 649-2779

  // The execution includes:
  // 1. Repository cloning
  // 2. Branch setup and switching
  // 3. CLAUDE.md preparation
  // 4. Claude command execution
  // 5. Result verification and PR/comment creation
  // 6. Log attachment if enabled

  // This is a placeholder - the full implementation would be extracted from solve.mjs
  throw new Error('Full execution logic implementation needed - extracted from lines 649-2779 of solve.mjs');
};

// Use getResourceSnapshot from memory-check module
export const getResourceSnapshot = memoryCheck.getResourceSnapshot;